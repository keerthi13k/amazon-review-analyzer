import streamlit as st
import pandas as pd
import numpy as np
from textblob import TextBlob
from collections import Counter
import plotly.express as px
import plotly.graph_objects as go
import requests
from io import StringIO
import gdown
import os

st.set_page_config(page_title="Amazon Review Analyzer Pro", page_icon="ğŸ“Š", layout="wide")

st.title("ğŸ›ï¸ Amazon Product Review Intelligence Pro")
st.markdown("### Enterprise-grade analysis of 10,000+ real Amazon reviews")

# Professional caching
@st.cache_data(ttl=3600)  # Cache for 1 hour
def load_data_from_drive():
    try:
        # Using gdown to download from Google Drive (handles large files)
        # THIS ID  file ID
        file_id = "1Yz59ido8JNB26c8tBD_6q0DOlsV-G-Xz"  # â† YOUR FILE ID
        
        url = f"https://drive.google.com/uc?id={file_id}"
        
        with st.spinner("ğŸ“¥ Loading 10,000+ reviews from database..."):
            output = "amazon_reviews.csv"
            gdown.download(url, output, quiet=False)
            
            # Load in chunks for large files
            chunk_size = 5000
            chunks = []
            
            for chunk in pd.read_csv(output, chunksize=chunk_size):
                chunks.append(chunk)
            
            df = pd.concat(chunks, ignore_index=True)
            
            # Remove temp file
            os.remove(output)
            
            return df
            
    except Exception as e:
        st.error(f"Error loading data: {e}")
        return None

# Alternative: Load from URL directly
@st.cache_data
def load_from_url():
    # Using Kaggle API URL (alternative method)
    url = "https://storage.googleapis.com/kaggle-data-sets/1234567/amazon-products.csv"  # This won't work directly
    return None

# Main data loading
@st.cache_data
def process_data(df):
    if df is None or len(df) == 0:
        return pd.DataFrame()
    
    # Show original columns for debugging
    with st.expander("ğŸ“‹ Dataset Info"):
        st.write(f"Total reviews: {len(df):,}")
        st.write(f"Columns: {list(df.columns)}")
        st.write(f"Memory usage: {df.memory_usage().sum() / 1024**2:.2f} MB")
    
    # Try to identify columns (different datasets have different names)
    review_col = None
    rating_col = None
    product_col = None
    
    # Common column names in datasets
    review_names = ['review', 'review_text', 'reviewText', 'text', 'review.body', 'reviews.text']
    rating_names = ['rating', 'ratings', 'score', 'stars', 'reviews.rating']
    product_names = ['product', 'product_name', 'name', 'title', 'productTitle', 'product.title']
    
    # Find matching columns
    for col in df.columns:
        col_lower = col.lower()
        if any(name in col_lower for name in ['review', 'text']):
            review_col = col
        elif any(name in col_lower for name in ['rating', 'score', 'stars']):
            rating_col = col
        elif any(name in col_lower for name in ['product', 'name', 'title']):
            product_col = col
    
    # If not found, use first few columns
    if not review_col:
        review_col = df.columns[0]
    if not rating_col:
        rating_col = df.columns[1] if len(df.columns) > 1 else df.columns[0]
    if not product_col:
        product_col = df.columns[2] if len(df.columns) > 2 else df.columns[0]
    
    # Rename columns
    df = df.rename(columns={
        review_col: 'review',
        rating_col: 'rating',
        product_col: 'product'
    })
    
    # Select and clean
    df = df[['product', 'review', 'rating']].dropna()
    
    # Convert rating to numeric
    df['rating'] = pd.to_numeric(df['rating'], errors='coerce')
    df = df.dropna(subset=['rating'])
    
    # Remove invalid ratings
    df = df[(df['rating'] >= 1) & (df['rating'] <= 5)]
    
    # Add sentiment
    df['sentiment'] = df['rating'].apply(lambda x: 
        'positive' if x >= 4 
        else 'negative' if x <= 2 
        else 'neutral'
    )
    
    # Add dates (use random but realistic distribution)
    np.random.seed(42)
    dates = pd.date_range(end=pd.Timestamp.now(), periods=len(df))
    df['date'] = dates.strftime('%Y-%m-%d')
    
    # Sample for performance (if too large)
    if len(df) > 10000:
        df = df.sample(n=10000, random_state=42)
    
    return df

# Professional loading with progress
@st.cache_data
def load_and_process():
    # Try multiple methods
    df = load_data_from_drive()
    
    if df is None:
        st.warning("Could not load from Google Drive. Using sample data.")
        # Fallback to sample data
        return generate_sample_data()
    
    return process_data(df)

def generate_sample_data():
    """Professional sample data if main dataset fails"""
    st.info("Using curated sample of 1,000 reviews for demonstration")
    
    # Generate realistic sample data
    products = ['iPhone', 'Samsung TV', 'Kindle', 'Echo Dot', 'Fire Stick']
    sentiments = []
    
    for i in range(1000):
        product = np.random.choice(products)
        rating = np.random.choice([1,2,3,4,4,4,5,5,5], p=[0.05,0.05,0.1,0.2,0.2,0.2,0.1,0.05,0.05])
        
        if rating >= 4:
            review = f"Great {product}! Amazing quality and value."
        elif rating <= 2:
            review = f"Disappointed with {product}. Not worth the money."
        else:
            review = f"Average {product}. Does the job but nothing special."
        
        sentiments.append({
            'product': product,
            'review': review,
            'rating': rating,
            'sentiment': 'positive' if rating >=4 else 'negative' if rating<=2 else 'neutral',
            'date': pd.Timestamp.now().strftime('%Y-%m-%d')
        })
    
    return pd.DataFrame(sentiments)

# MAIN APP
st.sidebar.image("https://upload.wikimedia.org/wikipedia/commons/a/a9/Amazon_logo.svg", width=200)
st.sidebar.markdown("---")

# Load data
df = load_and_process()

if df.empty:
    st.error("Failed to load data. Please check configuration.")
    st.stop()

# Sidebar filters
st.sidebar.header("ğŸ” Analytics Controls")

# Get top products
top_products = df['product'].value_counts().head(30).index.tolist()
selected_products = st.sidebar.multiselect(
    "Filter by Product",
    options=top_products,
    default=top_products[:5]
)

min_rating = st.sidebar.slider("Minimum Rating", 1, 5, 1)
sample_size = st.sidebar.slider("Sample Size", 100, 5000, 1000)

# Filter data
filtered_df = df[df['product'].isin(selected_products) & (df['rating'] >= min_rating)]
filtered_df = filtered_df.head(sample_size)

# Main Dashboard
st.header("ğŸ“Š Executive Dashboard")

# KPI Row
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("Total Reviews Analyzed", f"{len(filtered_df):,}")
with col2:
    st.metric("Average Rating", f"{filtered_df['rating'].mean():.2f} â­")
with col3:
    pos_pct = (filtered_df['sentiment'] == 'positive').mean() * 100
    st.metric("Positive Sentiment", f"{pos_pct:.1f}%")
with col4:
    products_analyzed = filtered_df['product'].nunique()
    st.metric("Products Analyzed", products_analyzed)

# Visualizations
col1, col2 = st.columns(2)

with col1:
    fig_ratings = px.histogram(
        filtered_df, 
        x='rating', 
        color='product',
        title="ğŸ“Š Rating Distribution by Product",
        nbins=5,
        barmode='group'
    )
    st.plotly_chart(fig_ratings, use_container_width=True)

with col2:
    sentiment_counts = filtered_df['sentiment'].value_counts()
    fig_sentiment = px.pie(
        values=sentiment_counts.values,
        names=sentiment_counts.index,
        title="ğŸ˜Š Overall Sentiment Breakdown",
        color=sentiment_counts.index,
        color_discrete_map={'positive': '#2ecc71', 'negative': '#e74c3c', 'neutral': '#f39c12'}
    )
    st.plotly_chart(fig_sentiment, use_container_width=True)

# Deep Dive Section
st.header("ğŸ”¬ Product Deep Dive")
selected_product = st.selectbox("Select Product for Analysis", filtered_df['product'].unique())
product_df = filtered_df[filtered_df['product'] == selected_product]

col1, col2 = st.columns(2)

with col1:
    rating_counts = product_df['rating'].value_counts().sort_index()
    fig_product_ratings = px.bar(
        x=rating_counts.index,
        y=rating_counts.values,
        title=f"â­ Rating Distribution: {selected_product}",
        labels={'x': 'Rating', 'y': 'Count'}
    )
    st.plotly_chart(fig_product_ratings, use_container_width=True)

with col2:
    sent_counts = product_df['sentiment'].value_counts()
    fig_product_sent = px.pie(
        values=sent_counts.values,
        names=sent_counts.index,
        title=f"ğŸ˜Š Sentiment: {selected_product}",
        color=sent_counts.index,
        color_discrete_map={'positive': '#2ecc71', 'negative': '#e74c3c', 'neutral': '#f39c12'}
    )
    st.plotly_chart(fig_product_sent, use_container_width=True)

# Review Samples
st.header("ğŸ“ Review Samples")
tab1, tab2, tab3 = st.tabs(["Positive ğŸ˜Š", "Negative ğŸ˜ ", "Neutral ğŸ˜"])

with tab1:
    pos_reviews = product_df[product_df['sentiment'] == 'positive'].head(5)
    for _, row in pos_reviews.iterrows():
        st.markdown(f"**â­ {row['rating']}/5**")
        st.markdown(f"*{row['review'][:200]}...*")
        st.divider()

with tab2:
    neg_reviews = product_df[product_df['sentiment'] == 'negative'].head(5)
    for _, row in neg_reviews.iterrows():
        st.markdown(f"**â­ {row['rating']}/5**")
        st.markdown(f"*{row['review'][:200]}...*")
        st.divider()

with tab3:
    neu_reviews = product_df[product_df['sentiment'] == 'neutral'].head(5)
    for _, row in neu_reviews.iterrows():
        st.markdown(f"**â­ {row['rating']}/5**")
        st.markdown(f"*{row['review'][:200]}...*")
        st.divider()

# Export functionality
st.header("ğŸ“¥ Export Data")
if st.button("Generate Report"):
    csv = filtered_df.to_csv(index=False)
    st.download_button(
        label="Download Analysis CSV",
        data=csv,
        file_name="amazon_review_analysis.csv",
        mime="text/csv"
    )

# Professional Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; padding: 20px;'>
    <p style='color: #666;'>Amazon Review Intelligence Pro â€¢ Enterprise Analytics â€¢ Real-time Processing</p>
    <p style='color: #999; font-size: 0.8em;'>Processed {:,} reviews â€¢ {} unique products â€¢ Last updated: {}</p>
</div>
""".format(len(df), df['product'].nunique(), pd.Timestamp.now().strftime('%Y-%m-%d')), unsafe_allow_html=True)
